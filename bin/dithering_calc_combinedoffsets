#!/bin/python

import math
import scipy.optimize as opt
import numpy as np
import argparse

import pickle
import sys
import astropy.units as u
from astropy import wcs

import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib import cm
from matplotlib.colors import LogNorm
from matplotlib import rcParams
from astropy.io import fits
from astropy import table

from scipy.interpolate import interp2d
from scipy.interpolate import CloughTocher2DInterpolator
from scipy.interpolate import SmoothBivariateSpline
from scipy.optimize import fsolve
from scipy.optimize import minimize
from scipy.optimize import root

plt.rcParams['font.family'] = "sans-serif"       
plt.rcParams['xtick.labelsize'] = 14
plt.rcParams['ytick.labelsize'] = 14
plt.rcParams['lines.linewidth'] = 2

def fit_vecfunc(inputs):
    num_fibers           = len(selected_xs)
    num_dithering_points = len(selected_xs[0])
    F                    = np.empty((num_equations))
    sigma_vars           = inputs[num_fibers*4:]
    F_idx                = 0
    for i in range(num_fibers):
        input_idx = i * 4
        amplitude = inputs[input_idx]
        xo        = inputs[input_idx+1]
        yo        = inputs[input_idx+2]
        sigma     = inputs[input_idx+3]
        curr_xs   = selected_xs[i]
        curr_ys   = selected_ys[i]
        curr_signals = selected_signals[i]
        for j in range(num_dithering_points):
            curr_sigma = sigma + sigma_vars[j]
            # apply the penalties depending on the conditions
            if (curr_sigma < 30.) or (curr_sigma > 70.):
                val = 1e12
            elif amplitude < 1e-3:
                val = 1e12
            elif (xo<-30. or xo>30.) or (yo<-30. or yo>30.):
                val = 1e12
            else:
                val = np.sqrt(np.fabs(curr_signals[i]**2 - (calculate_integral(curr_xs[i], curr_ys[i], xo, yo, amplitude, curr_sigma))**2))
            
            F[F_idx] = val
            F_idx+=1
    return F
                                        
def calculate_integral(x_pos, y_pos, xo, yo, amp, sigma):
    max_x = max(x_pos, xo)+100
    min_x = min(x_pos, xo)-100
    max_y = max(y_pos, yo)+100
    min_y = min(y_pos, yo)-100
    xs = np.linspace(min_x, max_x, grid_sampling)
    ys = np.linspace(min_y, max_y, grid_sampling)
    dx = xs[1]-xs[0]
    dy = ys[1]-ys[0]
    xv, yv = np.meshgrid(xs, ys)
    integral = 0
    for i in range(grid_sampling):
        for j in range(grid_sampling):
            integral += integrand(xv[i,j], yv[i,j], x_pos, y_pos, amp, xo, yo, sigma)*dx*dy
    return integral

def integrand(x, y, x_offset, y_offset, amp, xo, yo, sigma):
    condition1 = (np.sqrt((x-x_offset)**2 + (y-y_offset)**2)) <=sigma
    condition2 = (np.sqrt((x-xo)**2       + (y-yo)**2)) <=sigma
    if condition1 and condition2:
        return twoDGaussian(x, y, amp, xo, yo, sigma, sigma)
    else:
        return 0

def twoDGaussian(x, y, amp, xo, yo, sigma_1, sigma_2, phi=0.0):
    A = (np.cos(phi) / sigma_1)**2 + (np.sin(phi) / sigma_2)**2
    B = (np.sin(phi) / sigma_1)**2 + (np.cos(phi) / sigma_2)**2
    C = 2 * np.sin(phi) * np.cos(phi)*(1/sigma_1**2 - 1/sigma_2**2)
    return amp * np.exp( -0.5 * ( A * (x-xo)**2 +
                                  B * (y-yo)**2 +
                                  C*(x-xo)*(y-yo) ) )

def run_analysis(pattern, search_radius1, search_radius2, search_radius3=None, template=1):
    filenames = []
    # two files to be combine by default
    # in case a third search radius is defined, add it to the list as well
    filenames.append("{}/{:.1f}um/result_{}_seeing0.00001_blur_wlenoffset-randoffset{}_combined_template{}.fits".format(data_path,
                                                                                                                                 search_radius1,
                                                                                                                                 pattern,
                                                                                                                                 template,
                                                                                                                                 template))
    filenames.append("{}/{:.1f}um/result_{}_seeing0.00001_blur_wlenoffset-randoffset{}_combined_template{}.fits".format(data_path,
                                                                                                                                 search_radius2,
                                                                                                                                 pattern,
                                                                                                                                 template,
                                                                                                                                 template))
    try:
        filenames.append("{}/{:.1f}um/result_{}_seeing0.00001_blur_wlenoffset-randoffset{}_combined_template{}.fits".format(data_path,
                                                                                                                                     search_radius3,
                                                                                                                                     pattern,
                                                                                                                                     template,
                                                                                                                                     template))
    except:
        pass

    dithering_pos_xs = []
    dithering_pos_ys = []
    calc_signals = []
    focal_xs     = []
    focal_ys     = []
    mags         = []
    
    # tables corresponding to the files
    for filename in filenames:
        hdus = fits.open(filename)
        dithering_pos_xs.append(hdus[1].data['dither_pos_x'])
        dithering_pos_ys.append(hdus[1].data['dither_pos_y'])
        calc_signals.append(hdus[1].data['calc_signals'])
        focal_xs.append(hdus[1].data['focal_x'])
        focal_ys.append(hdus[1].data['focal_y'])
        mags.append(hdus[1].data['mag'])
        
    calc_offsets_x = []
    calc_offsets_y = []

    global collected_xs, collected_ys, collected_signals, collected_focal_xs, collected_focal_ys
    per_dither        = 9
    collected_xs      = np.zeros((end_idx-start_idx+1, len(filenames)*per_dither))
    collected_ys      = np.zeros((end_idx-start_idx+1, len(filenames)*per_dither))
    collected_signals = np.zeros((end_idx-start_idx+1, len(filenames)*per_dither))
    collected_focal_x = np.zeros((end_idx-start_idx+1))
    collected_focal_y = np.zeros((end_idx-start_idx+1))
    for iFiber in range(start_idx, end_idx):
        collected_focal_x[iFiber]          = focal_xs[0][iFiber]
        collected_focal_y[iFiber]          = focal_ys[0][iFiber]
        collected_xs[iFiber][0:per_dither] = dithering_pos_xs[0][iFiber]
        collected_ys[iFiber][0:per_dither] = dithering_pos_ys[0][iFiber]
        collected_signals[iFiber][0:per_dither] =  calc_signals[0][iFiber]
        for iSet, _ in enumerate(dithering_pos_xs):
            if iSet == 0:
                continue
            focal_x_indices = (focal_xs[iSet] == collected_focal_x[iFiber])
            focal_y_indices = (focal_ys[iSet] == collected_focal_y[iFiber])
            index        = np.logical_and(focal_x_indices, focal_y_indices)
            ifiber_match = np.where(index)[0]
            # just a sanity check
            if ( (collected_focal_x[iFiber] == focal_xs[iSet][ifiber_match]) and (collected_focal_y[iFiber] == focal_ys[iSet][ifiber_match]) ):
                collected_xs[iFiber][iSet*9:(iSet+1)*9] = dithering_pos_xs[iSet][ifiber_match]
                collected_ys[iFiber][iSet*9:(iSet+1)*9] = dithering_pos_ys[iSet][ifiber_match]
                collected_signals[iFiber][iSet*9:(iSet+1)*9] = calc_signals[iSet][ifiber_match]
            else:
                print("failed the sanity check")
    # once all the coordinates and the signals are collected
    # we randomly group them in 10 (for now, it is not random)
    global num_unknowns, num_equations
    global selected_xs, selected_ys, selected_signals
    #num_in_group = 4
    # here we select the fibers
    selected_xs = collected_xs[:num_in_group]
    selected_ys = collected_ys[:num_in_group]
    selected_signals = collected_signals[:num_in_group]
    num_unknowns = num_in_group * 4 + len(selected_xs[0])
    num_equations = num_in_group * len(selected_xs[0])
    
    print("Number of unknowns: ", num_unknowns)
    print("Number of equations: ", num_equations)
    
    initial_guess = []
    for i in range(num_in_group):
        # initial guesses for amplitude, xo, yo, sigma per fiber
        initial_guess.extend((np.random.uniform(1e-2, 0.2),
                              np.random.uniform(-20., 20.),
                              np.random.uniform(-20., 20.),
                              np.random.uniform(30., 70.)))
    # change in the sigma per fiber is added here.
    # it is assumed all fibers exhibit the same change
    for i in range(len(selected_xs[0])):
        initial_guess.append(np.random.uniform(-5., 5.))

    # I will fill the rest of the initial guess with zero values
    # required for scipy.root to work
    curr_initial_guess_len = len(initial_guess)
    for i in range(num_equations-num_unknowns):
        initial_guess.append(1e-5)

    print("Initial cost   : ", np.sum(fit_vecfunc(initial_guess)))

    calc_values = root(fit_vecfunc, x0=initial_guess, method='lm',
                       options={'ftol': 1e-12, 'xtol':1e-12,
                                'eps': 7.5, 'gtol': 1e-12, 'maxiter': 5000})

    #print(fit_vecfunc(calc_values.x))
    #print(calc_values.x)
    print("Initial        : ")
    for i in range(num_in_group):
        print("A={}, xo={}, yo={}".format(initial_guess[i*4], initial_guess[i*4+1], initial_guess[i*4+2]))
    print("Solver message : ", calc_values.message)
    print("Convergence    : ", calc_values.success)
    print("Solution       : ")
    for i in range(num_in_group):
        print("A={}, xo={}, yo={}".format(calc_values.x[i*4], calc_values.x[i*4+1], calc_values.x[i*4+2]))
    print("Total cost     : ", np.sum(fit_vecfunc(calc_values.x)))
    
    for i in something:
        # this is where script will break
        print(r[0])
                
        initial_guess = [0.1, np.random.uniform(-20., 20.), np.random.uniform(-20., 20.), np.random.uniform(30., 70.)]
        bounds        = [(1e-1, 1.0), (-40., 40.), (-40., 40.), (30., 70.)]
        for iDither in range(len(curr_xs)):
            initial_guess.append(np.random.uniform(-5., 5.))
        #calc_values = minimize(proper_fit_func, x0=calc_values.x, method="TNC", bounds=tuple(bounds), tol=1e-8,
        #                       options={'maxiter': 5000, 'ftol':1e-8})
        calc_values = root(proper_fit_vecfunc, x0=initial_guess, method='lm',
                           options={'ftol': 1e-8, 'xtol':1e-8, 'maxiter': 5000})
        #calc_values = root(proper_fit_vecfunc, x0=calc_values.x, method='lm',
        #                   options={'ftol': 1e-10, 'xtol':1e-10, 'maxiter': 5000})
        print(initial_guess)
        print(iFiber, calc_values.success, calc_values.x[:])
        initial_guess[0] = initial_guess[0]/2.
        calc_values = root(proper_fit_vecfunc, x0=initial_guess, method='lm',
                           options={'ftol': 1e-8, 'xtol':1e-8, 'maxiter': 5000})

        calc_values = root(proper_fit_vecfunc, x0=calc_values.x, method='broyden1')#,
                           #options={'ftol': 1e-8, 'xtol':1e-8})#, 'maxiter': 5000})
        #calc_values = root(proper_fit_vecfunc, x0=calc_values.x, method='linearmixing',
        #                   options={'ftol': 1e-10, 'xtol':1e-10, 'maxiter': 5000})
        print(iFiber, calc_values.success, calc_values.x[:])

        
        calc_values = root(proper_fit_vecfunc, x0=initial_guess, method='linearmixing',
                           options={'ftol': 1e-8, 'xtol':1e-8, 'maxiter': 5000})
        #calc_values = root(proper_fit_vecfunc, x0=calc_values.x, method='linearmixing',
        #                   options={'ftol': 1e-10, 'xtol':1e-10, 'maxiter': 5000})
        print(iFiber, calc_values.success, calc_values.x[:])

        calc_x_offset = calc_values.x[1]
        calc_y_offset = calc_values.x[2]
        calc_offsets_x.append(calc_x_offset)
        calc_offsets_y.append(calc_y_offset)
        del curr_xs, curr_ys, curr_signals
        
    calc_offsets_x = np.array(calc_offsets_x)
    calc_offsets_y = np.array(calc_offsets_y)
    return focal_xs[0], focal_ys[0], calc_offsets_x, calc_offsets_y

def run(search_radius1, search_radius2, search_radius3=None, template=1, prefix=None):
    max_value = 30.
    
    # calculate the values for a combination of search radii
    focal_x, focal_y, calc_offset_x, calc_offset_y = run_analysis("triangle", 
                                                                  search_radius1,
                                                                  search_radius2,
                                                                  search_radius3,
                                                                  template=template)

    results_summary = {'focal_x': focal_x,
                       'focal_y': focal_y,
                       'calc_offset_x': calc_offset_x,
                       'calc_offset_y': calc_offset_y}
    pickle.dump(results_summary, open("results_{}_{}_summary_{}_{}.pkl".format(search_radius1, search_radius2, start_idx, end_idx), "wb"))
    
    # put the numbers into interpolators
    calc_offset_r = np.sqrt(calc_offset_x**2 + calc_offset_y**2)
    selected      = calc_offset_r <= max_value
    focal_xy      = list(zip(focal_x[selected], focal_y[selected]))
    interpolator_x = CloughTocher2DInterpolator(focal_xy, calc_offset_x[selected])
    interpolator_y = CloughTocher2DInterpolator(focal_xy, calc_offset_y[selected])

    # calculate the interpolated values at the grid points
    cx = interpolator_x(xys)
    cy = interpolator_y(xys)
    cr = np.sqrt(cx**2+cy**2)
    
    # draw the figure for calculated offsets less than 50um
    r = 410

    # calculate the interpolated values at the grid points
    cx_org = interpolator_org_x(xys)
    cy_org = interpolator_org_y(xys)
    cr_org = np.sqrt(cx_org**2+cy_org**2)

    # draw the figure for calculated offsets less than 50um
    diff_cx = cx_org-cx
    diff_cy = cy_org-cy
    selected3 = (diff_cx == diff_cx)
    diff_cr = np.sqrt(diff_cx**2 + diff_cy**2)

    sampling = 2
    sampling_check = np.full(len(cr), False)
    sampling_check[::sampling] = True
    nan_check_calc = cr==cr
    nan_check_in   = cr_org==cr_org
    nan_check_res  = diff_cr==diff_cr
    max_val_check  = cr<=max_value
    last_selection = np.logical_and(sampling_check,
                                    (np.logical_and(np.logical_and(nan_check_calc, nan_check_in),
                                                    np.logical_and(nan_check_res, max_val_check))))
    fig = plt.figure(figsize=(25, 25))

    cmap = cm.get_cmap('PuRd')
    norm = mpl.colors.Normalize(vmin=0.,vmax=max_value,clip=False)
    
    plt.subplot(221)
    plt.quiver(xs[last_selection], ys[last_selection],
               np.array(cx_org[last_selection]), np.array(cy_org[last_selection]),
               cr_org[last_selection], cmap=cmap, norm=norm)
    plt.gca().set_aspect('equal','datalim')
    plt.gca().add_artist(plt.Circle((0,0), r, color = 'r', fill=False))
    cbar = plt.colorbar(fraction=0.04, pad=0.04)
    cbar.set_label("Offsets [um]")
    plt.axis('off')
    plt.title("Input Offsets")
    plt.tight_layout()

    plt.subplot(222)
    plt.quiver(xs[last_selection], ys[last_selection],
               -np.array(cx[last_selection]), -np.array(cy[last_selection]),
               cr[last_selection], cmap=cmap, norm=norm)
    plt.gca().set_aspect('equal','datalim')
    plt.gca().add_artist(plt.Circle((0,0), r, color = 'r', fill=False))
    cbar = plt.colorbar(fraction=0.04, pad=0.04)
    cbar.set_label("Calc Offsets [um]")
    plt.axis('off')
    plt.title("Calculated Offsets")
    plt.tight_layout()
    if search_radius3 is None:
        plt.title("{:.1f}um + {:.1f}um Triangulation Pattern".format(search_radius1, search_radius2))
    else:
        plt.title("{:.1f}um + {:.1f}um +{:.1f}um Triangulation Pattern".format(search_radius1, search_radius2, search_radius3))

    plt.subplot(223)
    plt.quiver(xs[last_selection], ys[last_selection],
               np.array(diff_cx[last_selection]), np.array(diff_cy[last_selection]),
               diff_cr[last_selection], cmap=cmap, norm=norm)
    plt.gca().set_aspect('equal','datalim')
    plt.gca().add_artist(plt.Circle((0,0), r, color = 'r', fill=False))
    cbar = plt.colorbar(fraction=0.04, pad=0.04)
    cbar.set_label("Residual Offsets [um]")
    plt.axis('off')
    plt.title("Residuals")
    plt.tight_layout()

    plt.subplot(224)
    plt.hist(cr_org[last_selection], bins=100, label="known offsets", alpha=.5,
             normed=True, histtype='step', color='red', linewidth=3)
    plt.hist(diff_cr[last_selection], bins=100, label="Residuals", alpha=.5,
             normed=True, histtype='step', color='blue', linewidth=3)
    plt.legend()
    plt.xlabel("Offset [um]")
    if search_radius3 is None:
        plt.savefig("{}/results_for_{}_{}.png".format(prefix, search_radius1, search_radius2))
        plt.savefig("{}/results_for_{}_{}.pdf".format(prefix, search_radius1, search_radius2))
    else:
        plt.savefig("{}/results_for_{}_{}_{}.png".format(prefix, search_radius1, search_radius2, search_radius3))
        plt.savefig("{}/results_for_{}_{}_{}.pdf".format(prefix, search_radius1, search_radius2, search_radius3))
    plt.close(fig)

    fig = plt.figure(figsize=(6,6))
    plt.hist(cr_org[last_selection], bins=100, label="known offsets", alpha=.5,
             normed=True, cumulative=True, histtype='step', color='red', linewidth=3)
    plt.hist(diff_cr[last_selection], bins=100, label="Residuals", alpha=.5,
             normed=True, cumulative=True, histtype='step', color='blue', linewidth=3)
    plt.legend(loc=2)
    plt.xlabel("Offset [um]")
    if search_radius3 is None:
        plt.savefig("{}/results_for_{}_{}_cumulative.png".format(prefix, search_radius1, search_radius2))
        plt.savefig("{}/results_for_{}_{}_cumulative.pdf".format(prefix, search_radius1, search_radius2))
    else:
        plt.savefig("{}/results_for_{}_{}_{}_cumulative.png".format(prefix, search_radius1, search_radius2, search_radius3))
        plt.savefig("{}/results_for_{}_{}_{}_cumulative.pdf".format(prefix, search_radius1, search_radius2, search_radius3))
    plt.close(fig)
    
    results = {}
    results["calc_offset_x"] = cx
    results["calc_offset_y"] = cy
    results["calc_offset_r"] = cr
    results["known_offset_x"] = cx_org
    results["known_offset_y"] = cy_org
    results["known_offset_r"] = cr_org
    results["residual_x"] = diff_cx
    results["residual_y"] = diff_cy
    results["residual_r"] = diff_cr
    if search_radius3 is None:
        pickle.dump(results, open("results_{}_{}.pkl".format(search_radius1, search_radius2), "wb"))
    else:
        pickle.dump(results, open("results_{}_{}_{}.pkl".format(search_radius1, search_radius2, search_radius3), "wb"))

parser = argparse.ArgumentParser("Script to combine and analyze different search radii")
parser.add_argument("--stepsize", required=True, nargs="+", type=float)
parser.add_argument("--template",  required=True, type=int)
parser.add_argument("--prefix",    required=True, type=str)
parser.add_argument("--sampling", type=int, default=6)
parser.add_argument("--start_idx", type=int, required=True)
parser.add_argument("--end_idx", type=int, required=True)
parser.add_argument("--numgroup", type=int, default=2)
parsed_args = parser.parse_args()

global grid_sampling, start_idx, end_idx, num_in_group
data_path     = parsed_args.prefix
stepsizes     = np.asarray(parsed_args.stepsize)
template      = parsed_args.template
prefix        = parsed_args.prefix
grid_sampling = parsed_args.sampling
start_idx     = parsed_args.start_idx
end_idx       = parsed_args.end_idx
num_in_group  = parsed_args.numgroup

# load the predefined offset field interpolator
pickled_data = pickle.load(open("../data/offset_field{}_CT2D.pkl".format(template), "rb"))
xs = np.array(pickled_data["x"])
ys = np.array(pickled_data["y"])
xys = list(zip(xs, ys))
interpolator_org_x = pickled_data["interpolator_x"]
interpolator_org_y = pickled_data["interpolator_y"]

stepsize = [None, None, None]
for i, _ in enumerate(stepsizes):
    stepsize[i] = stepsizes[i]
run(*stepsize, template=template, prefix=prefix)

