#!/bin/python

import math
import scipy.optimize as opt
import numpy as np
import argparse

import pickle
import sys
import astropy.units as u
from astropy import wcs

import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib import cm
from matplotlib.colors import LogNorm
from matplotlib import rcParams
from astropy.io import fits
from astropy import table

from scipy.interpolate import interp2d
from scipy.interpolate import CloughTocher2DInterpolator
from scipy.interpolate import SmoothBivariateSpline
from scipy.optimize import fsolve
from scipy.optimize import minimize
from scipy.optimize import root

plt.rcParams['font.family'] = "sans-serif"       
plt.rcParams['xtick.labelsize'] = 14
plt.rcParams['ytick.labelsize'] = 14
plt.rcParams['lines.linewidth'] = 2

def calculate_integral(x_pos, y_pos, xo, yo, amp, sigma):
    max_x = max(x_pos, xo)+100
    min_x = min(x_pos, xo)-100
    max_y = max(y_pos, yo)+100
    min_y = min(y_pos, yo)-100
    xs = np.linspace(min_x, max_x, grid_sampling)
    ys = np.linspace(min_y, max_y, grid_sampling)
    dx = xs[1]-xs[0]
    dy = ys[1]-ys[0]
    xv, yv = np.meshgrid(xs, ys)
    integral = 0
    for i in range(grid_sampling):
        for j in range(grid_sampling):
            integral += integrand(xv[i,j], yv[i,j], x_pos, y_pos, amp, xo, yo, sigma)*dx*dy
    return integral

def integrand(x, y, x_offset, y_offset, amp, xo, yo, sigma):
    condition1 = (np.sqrt((x-x_offset)**2 + (y-y_offset)**2)) <=sigma
    condition2 = (np.sqrt((x-xo)**2       + (y-yo)**2)) <=sigma
    if condition1 and condition2:
        return twoDGaussian(x, y, amp, xo, yo, sigma, sigma)
    else:
        return 0

def twoDGaussian(x, y, amp, xo, yo, sigma_1, sigma_2, phi=0.0):
    A = (np.cos(phi) / sigma_1)**2 + (np.sin(phi) / sigma_2)**2
    B = (np.sin(phi) / sigma_1)**2 + (np.cos(phi) / sigma_2)**2
    C = 2 * np.sin(phi) * np.cos(phi)*(1/sigma_1**2 - 1/sigma_2**2)
    return amp * np.exp( -0.5 * ( A * (x-xo)**2 +
                                  B * (y-yo)**2 +
                                  C*(x-xo)*(y-yo) ) )

sigma_limits = [-5., 5.]
def proper_fit_vecfunc(inputs):
    num_dithering_points = len(curr_xs)
    amplitude = inputs[0]
    xo        = inputs[1]
    yo        = inputs[2]
    sigma     = inputs[3]
    sigmas    = inputs[4:]
    F         = np.empty((num_dithering_points+4))
    for iDither in range(num_dithering_points):
        condition = 0
        curr_sigma = sigma + sigmas[iDither]
        if (curr_sigma < 30.) or (curr_sigma > 70.):
            condition = 1
        if (sigmas[iDither] < sigma_limits[0]) or (sigmas[iDither] > sigma_limits[1]):
            condition = 2
        if amplitude < 1e-3:
            condition = 3
        if condition == 0:
            F[iDither] = calculate_integral(curr_xs[iDither], curr_ys[iDither], xo, yo, amplitude, curr_sigma)
            #g = np.fabs(curr_signals[iDither]**2 - \
            #            (amplitude * np.exp( - ( (curr_xs[iDither]-xo)**2/(2*curr_sigma**2) + (curr_ys[iDither]-yo)**2/(2*curr_sigma**2) ) ))**2)
            #F[iDither] = g.ravel()
            #print(curr_signals[iDither],
            #      (amplitude * np.exp( - ( (curr_xs[iDither]-xo)**2/(2*curr_sigma**2) + (curr_ys[iDither]-yo)**2/(2*curr_sigma**2) ) ))**2)
        else:
            F[iDither] = 1e12
    for iDummy in range(4):
        F[num_dithering_points+iDummy] = 1e-5
    return F

def run_analysis(pattern, search_radius1, search_radius2, search_radius3=None, template=1):
    filenames = []
    # two files to be combine by default
    # in case a third search radius is defined, add it to the list as well
    filenames.append("{}/{:.1f}um/result_{}_seeing0.00001_blur_wlenoffset-randoffset{}_combined_template{}.fits".format(data_path,
                                                                                                                                 search_radius1,
                                                                                                                                 pattern,
                                                                                                                                 template,
                                                                                                                                 template))
    filenames.append("{}/{:.1f}um/result_{}_seeing0.00001_blur_wlenoffset-randoffset{}_combined_template{}.fits".format(data_path,
                                                                                                                                 search_radius2,
                                                                                                                                 pattern,
                                                                                                                                 template,
                                                                                                                                 template))
    try:
        filenames.append("{}/{:.1f}um/result_{}_seeing0.00001_blur_wlenoffset-randoffset{}_combined_template{}.fits".format(data_path,
                                                                                                                                     search_radius3,
                                                                                                                                     pattern,
                                                                                                                                     template,
                                                                                                                                     template))
    except:
        pass

    dithering_pos_xs = []
    dithering_pos_ys = []
    calc_signals = []
    focal_xs     = []
    focal_ys     = []
    mags         = []
    
    # tables corresponding to the files
    for filename in filenames:
        hdus = fits.open(filename)
        dithering_pos_xs.append(hdus[1].data['dither_pos_x'])
        dithering_pos_ys.append(hdus[1].data['dither_pos_y'])
        calc_signals.append(hdus[1].data['calc_signals'])
        focal_xs.append(hdus[1].data['focal_x'])
        focal_ys.append(hdus[1].data['focal_y'])
        mags.append(hdus[1].data['mag'])
        
    calc_offsets_x = []
    calc_offsets_y = []

    #for iFiber in range(len(dithering_pos_xs[0])):
    for iFiber in range(start_idx, end_idx):#(focal_xs[0]):
        global curr_xs, curr_ys, curr_signals
        curr_focal_x = focal_xs[0][iFiber]
        curr_focal_y = focal_ys[0][iFiber]
        curr_xs = dithering_pos_xs[0][iFiber]
        curr_ys = dithering_pos_ys[0][iFiber]
        curr_signals = calc_signals[0][iFiber]
        for iSet, _ in enumerate(dithering_pos_xs):
            if iSet == 0:
                continue
            focal_x_indices = (focal_xs[iSet] == curr_focal_x)
            focal_y_indices = (focal_ys[iSet] == curr_focal_y)
            index        = np.logical_and(focal_x_indices, focal_y_indices)
            ifiber_match = np.where(index)[0]
            # just a sanity check
            if ( (curr_focal_x == focal_xs[iSet][ifiber_match]) and (curr_focal_y == focal_ys[iSet][ifiber_match]) ):
                curr_xs = np.concatenate((curr_xs, dithering_pos_xs[iSet][ifiber_match]), axis=None)
                curr_ys = np.concatenate((curr_ys, dithering_pos_ys[iSet][ifiber_match]), axis=None)
                curr_signals = np.concatenate((curr_signals, calc_signals[iSet][ifiber_match]), axis=None)
            else:
                print("failed the sanity check")
        curr_xs = np.asarray(curr_xs).flatten()
        curr_ys = np.asarray(curr_ys).flatten()
        curr_signals  = np.asarray(curr_signals).flatten()
        initial_guess = [np.random.uniform(1e-2, 0.2), np.random.uniform(-20., 20.), np.random.uniform(-20., 20.), np.random.uniform(30., 70.)]
        bounds        = [(1e-1, 1.0), (-40., 40.), (-40., 40.), (30., 70.)]
        for iDither in range(len(curr_xs)):
            initial_guess.append(np.random.uniform(-5., 5.))
        calc_values = root(proper_fit_vecfunc, x0=initial_guess,
                           method='lm',
                           options={'ftol': 1e-15, 'xtol':1e-15,
                                    'factor': 100, 'eps': 5.,
                                    'gtol': 1e-15, 'maxiter': 10000})
        print("Fiber ID      i ", Fiber)
        print("Solver message: ", calc_values.message)
        print("Convergence   : ", calc_values.success)
        print("Num of F ev   : ", calc_values.nfev)
        print("Fit results   : ", proper_fit_vecfunc(calc_values.x))
        
        calc_x_offset = calc_values.x[1]
        calc_y_offset = calc_values.x[2]
        calc_offsets_x.append(calc_x_offset)
        calc_offsets_y.append(calc_y_offset)
        del curr_xs, curr_ys, curr_signals
        
    calc_offsets_x = np.array(calc_offsets_x)
    calc_offsets_y = np.array(calc_offsets_y)
    return focal_xs[0], focal_ys[0], calc_offsets_x, calc_offsets_y

def run(search_radius1, search_radius2, search_radius3=None, template=1, prefix=None):
    max_value = 30.
    
    # calculate the values for a combination of search radii
    focal_x, focal_y, calc_offset_x, calc_offset_y = run_analysis("triangle", 
                                                                  search_radius1,
                                                                  search_radius2,
                                                                  search_radius3,
                                                                  template=template)

    results_summary = {'focal_x': focal_x,
                       'focal_y': focal_y,
                       'calc_offset_x': calc_offset_x,
                       'calc_offset_y': calc_offset_y}
    pickle.dump(results_summary, open("results_{}_{}_summary_{}_{}.pkl".format(search_radius1, search_radius2, start_idx, end_idx), "wb"))

    """
    # put the numbers into interpolators
    calc_offset_r = np.sqrt(calc_offset_x**2 + calc_offset_y**2)
    selected      = calc_offset_r <= max_value
    focal_xy      = list(zip(focal_x[selected], focal_y[selected]))
    interpolator_x = CloughTocher2DInterpolator(focal_xy, calc_offset_x[selected])
    interpolator_y = CloughTocher2DInterpolator(focal_xy, calc_offset_y[selected])

    # calculate the interpolated values at the grid points
    cx = interpolator_x(xys)
    cy = interpolator_y(xys)
    cr = np.sqrt(cx**2+cy**2)
    
    # draw the figure for calculated offsets less than 50um
    r = 410

    # calculate the interpolated values at the grid points
    cx_org = interpolator_org_x(xys)
    cy_org = interpolator_org_y(xys)
    cr_org = np.sqrt(cx_org**2+cy_org**2)

    # draw the figure for calculated offsets less than 50um
    diff_cx = cx_org-cx
    diff_cy = cy_org-cy
    selected3 = (diff_cx == diff_cx)
    diff_cr = np.sqrt(diff_cx**2 + diff_cy**2)

    sampling = 2
    sampling_check = np.full(len(cr), False)
    sampling_check[::sampling] = True
    nan_check_calc = cr==cr
    nan_check_in   = cr_org==cr_org
    nan_check_res  = diff_cr==diff_cr
    max_val_check  = cr<=max_value
    last_selection = np.logical_and(sampling_check,
                                    (np.logical_and(np.logical_and(nan_check_calc, nan_check_in),
                                                    np.logical_and(nan_check_res, max_val_check))))
    fig = plt.figure(figsize=(25, 25))

    cmap = cm.get_cmap('PuRd')
    norm = mpl.colors.Normalize(vmin=0.,vmax=max_value,clip=False)
    
    plt.subplot(221)
    plt.quiver(xs[last_selection], ys[last_selection],
               np.array(cx_org[last_selection]), np.array(cy_org[last_selection]),
               cr_org[last_selection], cmap=cmap, norm=norm)
    plt.gca().set_aspect('equal','datalim')
    plt.gca().add_artist(plt.Circle((0,0), r, color = 'r', fill=False))
    cbar = plt.colorbar(fraction=0.04, pad=0.04)
    cbar.set_label("Offsets [um]")
    plt.axis('off')
    plt.title("Input Offsets")
    plt.tight_layout()

    plt.subplot(222)
    plt.quiver(xs[last_selection], ys[last_selection],
               -np.array(cx[last_selection]), -np.array(cy[last_selection]),
               cr[last_selection], cmap=cmap, norm=norm)
    plt.gca().set_aspect('equal','datalim')
    plt.gca().add_artist(plt.Circle((0,0), r, color = 'r', fill=False))
    cbar = plt.colorbar(fraction=0.04, pad=0.04)
    cbar.set_label("Calc Offsets [um]")
    plt.axis('off')
    plt.title("Calculated Offsets")
    plt.tight_layout()
    if search_radius3 is None:
        plt.title("{:.1f}um + {:.1f}um Triangulation Pattern".format(search_radius1, search_radius2))
    else:
        plt.title("{:.1f}um + {:.1f}um +{:.1f}um Triangulation Pattern".format(search_radius1, search_radius2, search_radius3))

    plt.subplot(223)
    plt.quiver(xs[last_selection], ys[last_selection],
               np.array(diff_cx[last_selection]), np.array(diff_cy[last_selection]),
               diff_cr[last_selection], cmap=cmap, norm=norm)
    plt.gca().set_aspect('equal','datalim')
    plt.gca().add_artist(plt.Circle((0,0), r, color = 'r', fill=False))
    cbar = plt.colorbar(fraction=0.04, pad=0.04)
    cbar.set_label("Residual Offsets [um]")
    plt.axis('off')
    plt.title("Residuals")
    plt.tight_layout()

    plt.subplot(224)
    plt.hist(cr_org[last_selection], bins=100, label="known offsets", alpha=.5,
             normed=True, histtype='step', color='red', linewidth=3)
    plt.hist(diff_cr[last_selection], bins=100, label="Residuals", alpha=.5,
             normed=True, histtype='step', color='blue', linewidth=3)
    plt.legend()
    plt.xlabel("Offset [um]")
    if search_radius3 is None:
        plt.savefig("{}/results_for_{}_{}.png".format(prefix, search_radius1, search_radius2))
        plt.savefig("{}/results_for_{}_{}.pdf".format(prefix, search_radius1, search_radius2))
    else:
        plt.savefig("{}/results_for_{}_{}_{}.png".format(prefix, search_radius1, search_radius2, search_radius3))
        plt.savefig("{}/results_for_{}_{}_{}.pdf".format(prefix, search_radius1, search_radius2, search_radius3))
    plt.close(fig)

    fig = plt.figure(figsize=(6,6))
    plt.hist(cr_org[last_selection], bins=100, label="known offsets", alpha=.5,
             normed=True, cumulative=True, histtype='step', color='red', linewidth=3)
    plt.hist(diff_cr[last_selection], bins=100, label="Residuals", alpha=.5,
             normed=True, cumulative=True, histtype='step', color='blue', linewidth=3)
    plt.legend(loc=2)
    plt.xlabel("Offset [um]")
    if search_radius3 is None:
        plt.savefig("{}/results_for_{}_{}_cumulative.png".format(prefix, search_radius1, search_radius2))
        plt.savefig("{}/results_for_{}_{}_cumulative.pdf".format(prefix, search_radius1, search_radius2))
    else:
        plt.savefig("{}/results_for_{}_{}_{}_cumulative.png".format(prefix, search_radius1, search_radius2, search_radius3))
        plt.savefig("{}/results_for_{}_{}_{}_cumulative.pdf".format(prefix, search_radius1, search_radius2, search_radius3))
    plt.close(fig)
    
    results = {}
    results["calc_offset_x"] = cx
    results["calc_offset_y"] = cy
    results["calc_offset_r"] = cr
    results["known_offset_x"] = cx_org
    results["known_offset_y"] = cy_org
    results["known_offset_r"] = cr_org
    results["residual_x"] = diff_cx
    results["residual_y"] = diff_cy
    results["residual_r"] = diff_cr
    if search_radius3 is None:
        pickle.dump(results, open("results_{}_{}.pkl".format(search_radius1, search_radius2), "wb"))
    else:
        pickle.dump(results, open("results_{}_{}_{}.pkl".format(search_radius1, search_radius2, search_radius3), "wb"))
    """
    
parser = argparse.ArgumentParser("Script to combine and analyze different search radii")
parser.add_argument("--stepsize", required=True, nargs="+", type=float)
parser.add_argument("--template",  required=True, type=int)
parser.add_argument("--prefix",    required=True, type=str)
parser.add_argument("--sampling", type=int, default=6)
parser.add_argument("--start_idx", type=int, required=True)
parser.add_argument("--end_idx", type=int, required=True)
parsed_args = parser.parse_args()

global grid_sampling, start_idx, end_idx
data_path     = parsed_args.prefix
stepsizes     = np.asarray(parsed_args.stepsize)
template      = parsed_args.template
prefix        = parsed_args.prefix
grid_sampling = parsed_args.sampling
start_idx     = parsed_args.start_idx
end_idx       = parsed_args.end_idx

# load the predefined offset field interpolator
pickled_data = pickle.load(open("../data/offset_field{}_CT2D.pkl".format(template), "rb"))
xs = np.array(pickled_data["x"])
ys = np.array(pickled_data["y"])
xys = list(zip(xs, ys))
interpolator_org_x = pickled_data["interpolator_x"]
interpolator_org_y = pickled_data["interpolator_y"]

stepsize = [None, None, None]
for i, _ in enumerate(stepsizes):
    stepsize[i] = stepsizes[i]
run(*stepsize, template=template, prefix=prefix)

