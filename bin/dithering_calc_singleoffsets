#!/bin/python

import math
import scipy.optimize as opt
import numpy as np
import argparse

import pickle
import sys
import astropy.units as u
from astropy import wcs

import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib import cm
from matplotlib.colors import LogNorm
from matplotlib import rcParams
from astropy.io import fits
from astropy import table

from scipy.interpolate import interp2d
from scipy.interpolate import CloughTocher2DInterpolator
from scipy.interpolate import SmoothBivariateSpline
from scipy.optimize import fsolve
from scipy.optimize import minimize
from scipy.optimize import root

plt.rcParams['font.family'] = "sans-serif"       
plt.rcParams['xtick.labelsize'] = 14
plt.rcParams['ytick.labelsize'] = 14
plt.rcParams['lines.linewidth'] = 2

global grid_sampling#, start_idx, end_idx

def calculate_integral(x_pos, y_pos, xo, yo, amp, sigma):
    max_x = max(x_pos, xo)+100
    min_x = min(x_pos, xo)-100
    max_y = max(y_pos, yo)+100
    min_y = min(y_pos, yo)-100
    xs = np.linspace(min_x, max_x, grid_sampling)
    ys = np.linspace(min_y, max_y, grid_sampling)
    dx = xs[1]-xs[0]
    dy = ys[1]-ys[0]
    xv, yv = np.meshgrid(xs, ys)
    integral = 0
    for i in range(grid_sampling):
        for j in range(grid_sampling):
            integral += integrand(xv[i,j], yv[i,j], x_pos, y_pos, amp, xo, yo, sigma)*dx*dy
    return integral

def integrand(x, y, x_offset, y_offset, amp, xo, yo, sigma):
    condition1 = (np.sqrt((x-x_offset)**2 + (y-y_offset)**2)) <=sigma
    condition2 = (np.sqrt((x-xo)**2       + (y-yo)**2)) <=sigma
    if condition1 and condition2:
        return twoDGaussian(x, y, amp, xo, yo, sigma, sigma)
    else:
        return 0

def twoDGaussian(x, y, amp, xo, yo, sigma_1, sigma_2, phi=0.0):
    A = (np.cos(phi) / sigma_1)**2 + (np.sin(phi) / sigma_2)**2
    B = (np.sin(phi) / sigma_1)**2 + (np.cos(phi) / sigma_2)**2
    C = 2 * np.sin(phi) * np.cos(phi)*(1/sigma_1**2 - 1/sigma_2**2)
    return amp * np.exp( -0.5 * ( A * (x-xo)**2 +
                                  B * (y-yo)**2 +
                                  C*(x-xo)*(y-yo) ) )

sigma_limits = [-5., 5.]
def proper_fit_vecfunc(inputs):
    if not np.asarray(inputs).all():
        print("Signals       : ", curr_signals)
    num_dithering_points = len(curr_xs)
    amplitude = inputs[0]
    xo        = inputs[1]
    yo        = inputs[2]
    sigma     = inputs[3]
    sigmas    = inputs[4:]
    F         = np.empty((num_dithering_points+4))
    for iDither in range(num_dithering_points):
        condition = 0
        curr_sigma = sigma + sigmas[iDither]
        if (curr_sigma < 30.) or (curr_sigma > 70.):
            condition = 1
        if (sigmas[iDither] < sigma_limits[0]) or (sigmas[iDither] > sigma_limits[1]):
            condition = 2
        if (amplitude < 1e-3):
            condition = 3
        if condition == 0:
            F[iDither] = np.sqrt(np.fabs(curr_signals[iDither]**2 -
                                         (calculate_integral(curr_xs[iDither], curr_ys[iDither], xo, yo, amplitude, curr_sigma))**2))
        else:
            F[iDither] = 1e12
    for iDummy in range(4):
        F[num_dithering_points+iDummy] = 1e-5
    return F

def run_analysis(pattern, search_radius1, search_radius2, search_radius3=None, template=1):
    filenames = []
    # two files to be combine by default
    # in case a third search radius is defined, add it to the list as well
    filenames.append("{}/{:.1f}um/result_{}_seeing0.00001_blur_wlenoffset-randoffset{}_combined_template{}.fits".format(data_path,
                                                                                                                                 search_radius1,
                                                                                                                                 pattern,
                                                                                                                                 template,
                                                                                                                                 template))
    filenames.append("{}/{:.1f}um/result_{}_seeing0.00001_blur_wlenoffset-randoffset{}_combined_template{}.fits".format(data_path,
                                                                                                                                 search_radius2,
                                                                                                                                 pattern,
                                                                                                                                 template,
                                                                                                                                 template))
    try:
        filenames.append("{}/{:.1f}um/result_{}_seeing0.00001_blur_wlenoffset-randoffset{}_combined_template{}.fits".format(data_path,
                                                                                                                                     search_radius3,
                                                                                                                                     pattern,
                                                                                                                                     template,
                                                                                                                                     template))
    except:
        pass

    dithering_pos_xs = []
    dithering_pos_ys = []
    calc_signals = []
    focal_xs     = []
    focal_ys     = []
    mags         = []
    
    # tables corresponding to the files
    for filename in filenames:
        hdus = fits.open(filename)
        dithering_pos_xs.append(hdus[1].data['dither_pos_x'])
        dithering_pos_ys.append(hdus[1].data['dither_pos_y'])
        calc_signals.append(hdus[1].data['calc_signals'])
        focal_xs.append(hdus[1].data['focal_x'])
        focal_ys.append(hdus[1].data['focal_y'])
        mags.append(hdus[1].data['mag'])
        
    calc_offsets_x   = []
    calc_offsets_y   = []
    calc_sigma       = []
    calc_delta_sigma = []
    calc_amplitude   = []
    calc_convergence = []
    calc_cost        = []
    #for iFiber in range(len(dithering_pos_xs[0])):
    for iFiber in range(start_idx, end_idx):
        global curr_xs, curr_ys, curr_signals
        curr_focal_x = focal_xs[0][iFiber]
        curr_focal_y = focal_ys[0][iFiber]
        curr_xs = dithering_pos_xs[0][iFiber]
        curr_ys = dithering_pos_ys[0][iFiber]
        curr_signals = calc_signals[0][iFiber]
        for iSet, _ in enumerate(dithering_pos_xs):
            if iSet == 0:
                continue
            focal_x_indices = (focal_xs[iSet] == curr_focal_x)
            focal_y_indices = (focal_ys[iSet] == curr_focal_y)
            index        = np.logical_and(focal_x_indices, focal_y_indices)
            ifiber_match = np.where(index)[0]
            # just a sanity check
            if ( (curr_focal_x == focal_xs[iSet][ifiber_match]) and (curr_focal_y == focal_ys[iSet][ifiber_match]) ):
                curr_xs = np.concatenate((curr_xs, dithering_pos_xs[iSet][ifiber_match]), axis=None)
                curr_ys = np.concatenate((curr_ys, dithering_pos_ys[iSet][ifiber_match]), axis=None)
                curr_signals = np.concatenate((curr_signals, calc_signals[iSet][ifiber_match]), axis=None)
            else:
                print("failed the sanity check")
        curr_xs = np.asarray(curr_xs).flatten()
        curr_ys = np.asarray(curr_ys).flatten()
        curr_signals  = np.asarray(curr_signals).flatten()
        retry = 0
        total_cost = 5000.
        while (retry < 50) and (total_cost>4000.):
            x_guess = np.sum(curr_xs * curr_signals)/np.sum(curr_signals)
            y_guess = np.sum(curr_ys * curr_signals)/np.sum(curr_signals)
            amp_guess = np.mean(curr_signals/100.)
            initial_guess = [amp_guess, x_guess, y_guess, np.random.uniform(30., 70.)]
            for iDither in range(len(curr_xs)):
                initial_guess.append(np.random.uniform(-5., 5.))
            total_cost = np.sum(proper_fit_vecfunc(initial_guess))
            retry     +=1
        print("Fiber ID      : ", iFiber)
        proper_fit_vecfunc(np.zeros(len(initial_guess)))
        print("Initial cost  : ", np.sum(proper_fit_vecfunc(initial_guess)))
        calc_values = root(proper_fit_vecfunc, x0=initial_guess,
                           method='lm',
                           options={'ftol': 1e-15, 'xtol':1e-15,
                                    'factor': 50, 'eps': 10.,
                                    'gtol': 1e-15, 'maxiter': 5000})
        print("Solver message: ", calc_values.message)
        print("Convergence   : ", calc_values.success)
        print("Num of F ev   : ", calc_values.nfev)
        print("Solution      : A={} x={} y={}".format(calc_values.x[0], calc_values.x[1], calc_values.x[2]))
        print("              : PSF={}".format(calc_values.x[3]))
        print("              : delta(PSF)=", calc_values.x[4:])
        print("Fit results   : ", proper_fit_vecfunc(calc_values.x))
        print("Total cost    : ", np.sum(proper_fit_vecfunc(calc_values.x)))
        
        calc_x_offset = calc_values.x[1]
        calc_y_offset = calc_values.x[2]
        calc_offsets_x.append(calc_x_offset)
        calc_offsets_y.append(calc_y_offset)
        calc_sigma.append(calc_values.x[3])
        calc_delta_sigma.append(calc_values.x[4:])
        calc_convergence.append(calc_values.success)
        calc_amplitude.append(calc_values.x[0])
        calc_cost.append(np.sum(proper_fit_vecfunc(calc_values.x)))
        del curr_xs, curr_ys, curr_signals
        
    calc_offsets_x = np.array(calc_offsets_x)
    calc_offsets_y = np.array(calc_offsets_y)

    return focal_xs[0], focal_ys[0], calc_offsets_x, calc_offsets_y, calc_sigma, calc_delta_sigma, calc_amplitude, calc_convergence, calc_cost

def run(search_radius1, search_radius2, search_radius3=None, start_idx=0, end_idx=1, template=1, prefix=None, grid_sampling=20):
    max_value = 30.
    
    # calculate the values for a combination of search radii
    focal_x, focal_y, calc_offset_x, calc_offset_y, calc_sigma, \
        calc_delta_sigma, calc_amplitude, calc_convergence, calc_cost = run_analysis("triangle", 
                                                                                               search_radius1,
                                                                                               search_radius2,
                                                                                               search_radius3,
                                                                                               template=template)

    results_summary = {'focal_x': focal_x,
                       'focal_y': focal_y,
                       'calc_offset_x': calc_offset_x,
                       'calc_offset_y': calc_offset_y,
                       'calc_sigma': calc_sigma,
                       'calc_delta_sigma': calc_delta_sigma,
                       'calc_amplitude': calc_amplitude,
                       'calc_convergence': calc_convergence,
                       'calc_cost': calc_cost}
    pickle.dump(results_summary, open("results_{}_{}_summary_{}_{}.pkl".format(search_radius1, search_radius2, start_idx, end_idx), "wb"))

if __name__ == "__main__":
    parser = argparse.ArgumentParser("Script to combine and analyze different search radii")
    parser.add_argument("--stepsize", required=True, nargs="+", type=float)
    parser.add_argument("--template",  required=True, type=int)
    parser.add_argument("--prefix",    required=True, type=str)
    parser.add_argument("--sampling", type=int, default=6)
    parser.add_argument("--start_idx", type=int, required=True)
    parser.add_argument("--end_idx", type=int, required=True)
    parsed_args = parser.parse_args()

    data_path     = parsed_args.prefix
    stepsizes     = np.asarray(parsed_args.stepsize)
    template      = parsed_args.template
    prefix        = parsed_args.prefix
    grid_sampling = parsed_args.sampling
    start_idx     = parsed_args.start_idx
    end_idx       = parsed_args.end_idx
    
    # load the predefined offset field interpolator
    pickled_data = pickle.load(open("../data/offset_field{}_CT2D.pkl".format(template), "rb"))
    xs = np.array(pickled_data["x"])
    ys = np.array(pickled_data["y"])
    xys = list(zip(xs, ys))
    interpolator_org_x = pickled_data["interpolator_x"]
    interpolator_org_y = pickled_data["interpolator_y"]
    
    stepsize = [None, None, None]
    for i, _ in enumerate(stepsizes):
        stepsize[i] = stepsizes[i]
    run(*stepsize, start_idx=start_idx, end_idx=end_idx, template=template, prefix=prefix, grid_sampling=grid_sampling)

