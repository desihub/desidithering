#!/bin/python

import astropy.units as u
import numpy as np
import yaml
import random
import math
import sys
import os
import scipy.optimize as opt
import matplotlib.pyplot as plt

from astropy.io import fits
from astropy import table

from desidithering import dithering as Dithering
import argparse
import time

import pickle

from sklearn.neighbors import KDTree

import dithering_print_offsets

is_plot = False

# this function yields the residual for the number of equations
def system(x, b):
    return (SOE(x) - b)

def SOE(x):
    start_time = time.time()
    calculated_integrals = np.zeros(n_equations) if n_equations>n_unknowns else np.zeros(n_unknowns)
    for idx in range(n_fibers):
        # assign the parameters to easy-to-read variable names and do unit conversions
        offset_x = x[idx*2+0]*u.micron
        offset_y = x[idx*2+1]*u.micron
        offset_x_um = offset_x.value
        offset_y_um = offset_y.value
        offset_x_mm = offset_x.to(u.mm).value
        offset_y_mm = offset_y.to(u.mm).value
        #dithering[idx].desi.atmosphere.seeing_fwhm_ref = seeing
        for exp_idx in range(n_exposures):
            delta_seeing  = x[n_fibers*2+exp_idx*2+0]*u.arcsec
            delta_airmass = x[n_fibers*2+exp_idx*2+1]
            eqn_idx = idx*n_exposures + exp_idx
            dithering[neighbors[idx]].set_focal_position_simple(curr_focal_xs[idx]+offset_x_mm, curr_focal_ys[idx]+offset_y_mm)
            dithering[neighbors[idx]].place_fiber([curr_xs[eqn_idx]+offset_x_um, curr_ys[eqn_idx]+offset_y_um])
            dithering[neighbors[idx]].run_simulation('qso', *source, report=False, \
                                                     seeing_fwhm_ref_offset=delta_seeing,
                                                     airmass_offset=delta_airmass)
            calculated_integrals[eqn_idx] = np.median(dithering[neighbors[idx]].signal['b'][0])
    return calculated_integrals
    
def run_analysis(pattern, search_radius1, search_radius2, search_radius3=None, start_idx=0, end_idx=1, template=1, seeing_rms=0.00001):
    global dithering
    global source
    global curr_xs, curr_ys, curr_focal_xs, curr_focal_ys, curr_signals
    global neighbors, n_fibers, n_exposures
    global n_equations, n_unknowns
    global seeing, airmass
    
    #correlation_distance = 2.0
    data_path = "../dithering-results"

    
    filenames = []
    # two files to be combine by default
    # in case a third search radius is defined, add it to the list as well
    filenames.append("{}/{:.1f}um/result_{}_seeing{}_blur_wlenoffset-randoffset{}_combined_template{}_updated.fits".format(data_path,
                                                                                                                           search_radius1,
                                                                                                                           pattern,
                                                                                                                           seeing_rms,
                                                                                                                           template,
                                                                                                                           template))
    filenames.append("{}/{:.1f}um/result_{}_seeing{}_blur_wlenoffset-randoffset{}_combined_template{}_updated.fits".format(data_path,
                                                                                                                           search_radius2,
                                                                                                                           pattern,
                                                                                                                           seeing_rms,
                                                                                                                           template,
                                                                                                                           template))
    try:
        filenames.append("{}/{:.1f}um/result_{}_seeing{}_blur_wlenoffset-randoffset{}_combined_template{}_updated.fits".format(data_path,
                                                                                                                               search_radius3,
                                                                                                                               pattern,
                                                                                                                               seeing_rms,
                                                                                                                               template,
                                                                                                                               template))
    except:
        pass

    print(" WILL PROCESS THE FOLLOWING FILES FOR OPTIMIZATION \n", filenames)
    
    dithering_pos_xs = []
    dithering_pos_ys = []
    fiber_ids    = []
    calc_signals = []
    focal_xs     = []
    focal_ys     = []
    mags         = []
    
    ## THIS PART IS PROBABLY NOT NEEDED
    ## CHECK BACK AGAIN
    # tables corresponding to the files
    for filename in filenames:
        hdus = fits.open(filename)
        dithering_pos_xs.append(hdus[1].data['dither_pos_x'])
        dithering_pos_ys.append(hdus[1].data['dither_pos_y'])
        fiber_ids.append(hdus[1].data['fiber_ids'])
        calc_signals.append(hdus[1].data['calc_signals_b'])
        focal_xs.append(hdus[1].data['focal_x'])
        focal_ys.append(hdus[1].data['focal_y'])
        mags.append(hdus[1].data['mag'])
        del hdus

    hdus = fits.open(filenames[0])
    f_ins   = hdus[1].data['f_in']
    w_first = 3500.0
    w_last  = 10000.0
    w_len   = len(f_ins[0])
    w_in    = np.linspace(w_first, w_last, w_len)

    #import matplotlib.pyplot as plt
    #plt.plot(w_ins, f_ins[0])
    #plt.show()
    
    focal_coordinates = np.vstack((focal_xs[0], focal_ys[0])).T
    tree = KDTree(focal_coordinates, leaf_size=4)
        
    input_focal_x    = []
    input_focal_y    = []
    printed_offsets_x= []
    printed_offsets_y= []
    calc_offsets_x   = []
    calc_offsets_y   = []
    calc_sigma       = []
    calc_delta_sigma = []
    calc_amplitude   = []
    calc_convergence = []
    calc_cost        = []
    exp_signals      = []
    opt_signals      = []
    
    for iFiber in range(start_idx, end_idx):

        print("Processing fiber: {}".format(iFiber))

        if True:
            curr_focal_xs = []
            curr_focal_ys = []

            curr_focal_x = focal_xs[0][iFiber]
            curr_focal_y = focal_ys[0][iFiber]

            neighbors = tree.query_radius(focal_coordinates[iFiber].reshape(1, 2), \
                                          r=correlation_distance, sort_results=True, return_distance=True)[0][0]
            if len(neighbors) > 3:
                neighbors = neighbors[:3]
            neighbors = np.hstack(([iFiber], neighbors[np.where(neighbors!=iFiber)]))
            n_fibers = len(neighbors)
            n_exposures = 9 * len(dithering_pos_xs)

            # create a dithering object for each fiber to speed up the computations
            dithering = {}
            for _, fiber_index in enumerate(neighbors):
                dithering_ = Dithering.dithering(config_file="config/desi-blur-wlenoffset-norandoffset.yaml")
                #w_in = tabled_wlens[fiber_index]
                #f_in = tabled_fluxes[fiber_index]
                dithering_.desi.source.update_in("bright star", 'star', w_in*u.angstrom, f_ins[fiber_index]*1e-17*u.erg/(u.angstrom*u.cm*u.cm*u.s))
                dithering_.desi.source.update_out()
                source = dithering_.generate_source(disk_fraction=0., bulge_fraction=0., half_light_disk=0., half_light_bulge=0.)
                dithering[fiber_index] = dithering_
                #del w_in, f_in,
                del dithering_
            print(dithering)
            
            # add the original fiber's data
            curr_xs = dithering_pos_xs[0][iFiber]
            curr_ys = dithering_pos_ys[0][iFiber]
            curr_signals = calc_signals[0][iFiber]
            curr_focal_xs.append(curr_focal_x)
            curr_focal_ys.append(curr_focal_y)
        
            for iSet, _ in enumerate(dithering_pos_xs):
                if iSet == 0:
                    continue
                focal_x_indices = (focal_xs[iSet] == curr_focal_x)
                focal_y_indices = (focal_ys[iSet] == curr_focal_y)
                index        = np.logical_and(focal_x_indices, focal_y_indices)
                ifiber_match = np.where(index)[0]
                # just a sanity check
                if ( (curr_focal_x == focal_xs[iSet][ifiber_match]) and (curr_focal_y == focal_ys[iSet][ifiber_match]) ):
                    curr_xs = np.concatenate((curr_xs, dithering_pos_xs[iSet][ifiber_match]), axis=None)
                    curr_ys = np.concatenate((curr_ys, dithering_pos_ys[iSet][ifiber_match]), axis=None)
                    curr_signals = np.concatenate((curr_signals, calc_signals[iSet][ifiber_match]), axis=None)
                else:
                    print("failed the sanity check")

            # add the neighboring fibers' data
            for _, nbr_idx in enumerate(neighbors):
                if nbr_idx == iFiber:
                    continue
                nbr_focal_x = focal_xs[0][nbr_idx]
                nbr_focal_y = focal_ys[0][nbr_idx]
                curr_xs = np.concatenate((curr_xs, dithering_pos_xs[0][nbr_idx]), axis=None)
                curr_ys = np.concatenate((curr_ys, dithering_pos_ys[0][nbr_idx]), axis=None)
                curr_signals = np.concatenate((curr_signals, calc_signals[0][nbr_idx]), axis=None)
                curr_focal_xs.append(nbr_focal_x)
                curr_focal_ys.append(nbr_focal_y)
                for iSet, _ in enumerate(dithering_pos_xs):
                    if iSet == 0:
                        continue
                    focal_x_indices = (focal_xs[iSet] == nbr_focal_x)
                    focal_y_indices = (focal_ys[iSet] == nbr_focal_y)
                    index        = np.logical_and(focal_x_indices, focal_y_indices)
                    ifiber_match = np.where(index)[0]
                    # just a sanity check
                    if ( (nbr_focal_x == focal_xs[iSet][ifiber_match]) and (nbr_focal_y == focal_ys[iSet][ifiber_match]) ):
                        curr_xs = np.concatenate((curr_xs, dithering_pos_xs[iSet][ifiber_match]), axis=None)
                        curr_ys = np.concatenate((curr_ys, dithering_pos_ys[iSet][ifiber_match]), axis=None)
                        curr_signals = np.concatenate((curr_signals, calc_signals[iSet][ifiber_match]), axis=None)
                    else:
                        print("failed the sanity check")

            n_equations = len(curr_xs)
            n_unknowns = 2*n_fibers + 2*n_exposures # (x_offset, y_offset) per fiber + delta(seeing) + delta(airmass)

            curr_signals = curr_signals if n_equations>=n_unknowns else np.concatenate((curr_signals, np.zeros(n_unknowns-n_equations)), axis=None)
        
            print("- Fiber ID:            {}".format(iFiber))
            print("- Number of neighbors: {}".format(len(neighbors)))
            print("-- Neighbors:          ", neighbors)
            print("- Number of fibers:    {}".format(n_fibers))
            print("- Number of exposures: {}".format(n_exposures))
            print("- Number of unknowns:  {}".format(n_unknowns))
            print("- Number of equations: {}".format(n_equations))

            curr_xs = np.asarray(curr_xs).flatten()
            curr_ys = np.asarray(curr_ys).flatten()
            curr_signals  = np.asarray(curr_signals).flatten()
            initial_guess = np.zeros(n_equations) if n_equations>=n_unknowns else np.zeros(n_unknowns)

            #x_guess = np.sum(curr_xs * curr_signals[:len(curr_xs)])/np.sum(curr_signals)
            #y_guess = np.sum(curr_ys * curr_signals[:len(curr_xs)])/np.sum(curr_signals)
            for idx in range(n_fibers):
                start_ = idx*n_exposures
                end_   = (idx+1)*n_exposures
                x_guess = np.sum(curr_xs[start_:end_] * curr_signals[start_:end_])/np.sum(curr_signals[start_:end_])
                y_guess = np.sum(curr_ys[start_:end_] * curr_signals[start_:end_])/np.sum(curr_signals[start_:end_])
                initial_guess[idx*2+0] = x_guess+np.random.uniform(-2., 2.)          # initial guess for the x-offset
                initial_guess[idx*2+1] = y_guess+np.random.uniform(-2., 2.)          # initial guess for the y-offset
            for idx in range(n_exposures):
                initial_guess[n_fibers*2+idx*2+0] = np.random.uniform(-0.1, 0.1)     # initial guess for the seeing change for that exposure
                initial_guess[n_fibers*2+idx*2+1] = np.random.uniform(-0.01, 0.01)   # initial guess for the airmass change for that exposure
            
            print("- Initial guess: \n", initial_guess[:n_unknowns])
            print("- Signals with initial guess: \n", SOE(initial_guess)[:n_equations])
            print("- Signals (measured): \n", curr_signals[:n_equations])
            
            solution = opt.root(system, initial_guess, args=curr_signals, method='lm', \
                                options={'factor': 100., 'xtol': 1e-3, 'eps': 5.})#, 'diag': 50*np.ones(n_equations)})
            solution_msg = solution.message
            solution_ier = solution.success
            solution_fev = solution.nfev
            solution     = solution
            print("- Solution: \n", solution.x[:n_unknowns])
            print("- Calculated (optimized) measurements: \n", SOE(np.asarray(solution.x))[:n_equations])
            print("- Relative errors for exposures: \n", (100*np.fabs(SOE(np.asarray(solution.x)) - curr_signals)/curr_signals)[:n_equations])
        
            printed_offset = dithering_print_offsets.print_offset(curr_focal_x, curr_focal_y)
            print("Solver message: ", solution_msg)
            print("Convergence   : ", solution_ier)
            print("Num of F ev   : ", solution_fev)
            print("Printed offset: ", printed_offset[0], printed_offset[1])
            print("Solution      : x={} y={}".format(solution.x[0], solution.x[1]))
            print("              : delta(seeing) ={}".format(solution.x[2*n_fibers:2*n_fibers+n_exposures]))

            input_focal_x.append(curr_focal_x)
            input_focal_y.append(curr_focal_y)
            printed_offsets_x.append(printed_offset[0])
            printed_offsets_y.append(printed_offset[1])
            calc_x_offset = solution.x[0]
            calc_y_offset = solution.x[1]
            calc_offsets_x.append(calc_x_offset)
            calc_offsets_y.append(calc_y_offset)
            calc_sigma.append(solution.x[3])
            calc_delta_sigma.append(solution.x[4*n_fibers:4*n_fibers+n_exposures])
            calc_convergence.append(solution.success)
            calc_amplitude.append(solution.x[2])
            calc_cost.append(None)    

            # here we calculate the signal at the original position
            # and then move the fiber and calculate the signal at the position of optimization
            dithering_orig = Dithering.dithering(config_file="config/desi-blur-wlenoffset-randoffset1.yaml")
            dithering_orig.desi.source.update_in("bright star", 'star', w_in*u.angstrom, f_ins[iFiber]*1e-17*u.erg/(u.angstrom*u.cm*u.cm*u.s))
            dithering_orig.desi.source.update_out()
            dithering_orig.set_focal_position_simple(curr_focal_x, curr_focal_y)
            dithering_orig.place_fiber([0., 0.])
            dithering_orig.run_simulation('qso', *source, report=False, \
                                          seeing_fwhm_ref_offset=0.*u.arcsec,
                                          airmass_offset=0.)
            print("Result at original position: ", np.median(dithering_orig.signal['b'][0]))
            dithering_orig.place_fiber([printed_offset[0], printed_offset[1]])
            dithering_orig.run_simulation('qso', *source, report=False, \
                                                       seeing_fwhm_ref_offset=solution.x[2*n_fibers]*u.arcsec,
                                                       airmass_offset=0.)
            exp_signal = np.median(dithering_orig.signal['b'][0])
            exp_signals.append(exp_signal)
            print("Result at expected position: ", exp_signal)
            dithering_orig.place_fiber([solution.x[0], solution.x[1]])
            dithering_orig.run_simulation('qso', *source, report=False, \
                                          seeing_fwhm_ref_offset=solution.x[2*n_fibers]*u.arcsec,
                                          airmass_offset=0.)
            opt_signal = np.median(dithering_orig.signal['b'][0])
            opt_signals.append(opt_signal)
            print("Result at calculated position: ", opt_signal)
        else:
            print(" -- PROBLEM WITH THE CURRENT CALCULATIONS ... ")
            continue
        
    calc_offsets_x = np.array(calc_offsets_x)
    calc_offsets_y = np.array(calc_offsets_y)
    exp_signals    = np.array(exp_signals)
    opt_signals    = np.array(opt_signals)
    
    return input_focal_x, input_focal_y, \
        calc_offsets_x, calc_offsets_y, calc_sigma, calc_delta_sigma, calc_amplitude, calc_convergence, calc_cost, \
        printed_offsets_x, printed_offsets_y, exp_signals, opt_signals

def run(search_radius1, search_radius2, search_radius3=None, start_idx=0, end_idx=1, template=1, prefix=None, seeing_rms=0.00001, pattern="random"):
    # calculate the values for a combination of search radii
    focal_x, focal_y, calc_offset_x, calc_offset_y, calc_sigma, \
        calc_delta_sigma, calc_amplitude, calc_convergence, calc_cost, \
        printed_offsets_x, printed_offsets_y, \
        exp_signals, opt_signals = run_analysis(pattern,
                                                search_radius1,
                                                search_radius2,
                                                search_radius3,
                                                start_idx=start_idx,
                                                end_idx=end_idx,
                                                template=template,
                                                seeing_rms=seeing_rms)
    results_summary = {'focal_x': focal_x,
                       'focal_y': focal_y,
                       'calc_offset_x': calc_offset_x,
                       'calc_offset_y': calc_offset_y,
                       'calc_sigma': calc_sigma,
                       'calc_delta_sigma': calc_delta_sigma,
                       'calc_amplitude': calc_amplitude,
                       'calc_convergence': calc_convergence,
                       'calc_cost': calc_cost,
                       'printed_offset_x': printed_offsets_x,
                       'printed_offset_y': printed_offsets_y,
                       'exp_signals': exp_signals,
                       'opt_signals': opt_signals}
    
    pickle.dump(results_summary, open("results_{}_{}_summary_{}_{}_new.pkl".format(search_radius1, search_radius2, start_idx, end_idx), "wb"))

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Script to find the optimal focal point given a set of parameters")
    parser.add_argument("--step-size",      dest="stepsize",             type=float,  required=True, \
                        help="Step size for the optimization algorithm", nargs="+")
    parser.add_argument("--lookupTable",    dest="LUT",                  type=str,    required=True, \
                        help="The table file to run the analysis")
    parser.add_argument("--seeing_offsets_rms",  dest="seeing_offsets",  type=str,  default=0.0, \
                        help="RMS of the seeing offsets")
    parser.add_argument("--start_idx",                                   type=int,    required=True)
    parser.add_argument("--end_idx",                                     type=int,    required=False, default=None)
    parser.add_argument("--dithering_pattern",   dest="pattern",         type=int,    default=0,\
                        help="Dithering pattern, 0: triangular, 1: rectangular, 2: random")
    parser.add_argument("--output",              dest="outfname",        type=str,    default="results")
    parser.add_argument("--prefix",              dest="prefix",          type=str,    default="",  required=False,\
                        help="The prefix for the output directory")
    parser.add_argument("--correlation_distance",dest="corrdist",        type=float,  default=2.0, required=False,\
                        help="Correlation distance to use for getting the nighbors")
    parser.add_argument("--verbose",             dest='verbose',         type=int,    default=0)
    parsed_args = parser.parse_args()

    global correlation_distance

    config_file          = "config/nooffsets.yaml"#desi-blur-wlenoffset-norandoffset.yaml"
    search_radius        = parsed_args.stepsize
    seeing_rms           = parsed_args.seeing_offsets
    outfname             = parsed_args.outfname
    start_idx            = parsed_args.start_idx
    end_idx              = parsed_args.end_idx if parsed_args.end_idx is not None else start_idx+1
    pattern              = parsed_args.pattern
    LUT_filename         = parsed_args.LUT
    prefix               = parsed_args.prefix
    correlation_distance = parsed_args.corrdist

    tabled_values = np.load(LUT_filename)
    tabled_wlens  = tabled_values["wlens"]
    tabled_fluxes = tabled_values["fluxes"]
    tabled_mags   = tabled_values["mags"]
    tabled_x_offsets = tabled_values['x_offsets']
    tabled_y_offsets = tabled_values['y_offsets']
    tabled_x_pos = tabled_values['x_pos']
    tabled_y_pos = tabled_values['y_pos']

    stepsize = [None, None, None]
    for i, _ in enumerate(search_radius):
        stepsize[i] = search_radius[i]
    run(*stepsize, start_idx=start_idx, end_idx=end_idx, template=1, prefix=prefix, seeing_rms=seeing_rms)

